rm(training, inTraining)
setwd("~/GitHub/hprice")
training = fread('train.csv', stringsAsFactors = TRUE)
test = fread('test.csv', stringsAsFactors = TRUE)
data = rbind(training, test, fill=TRUE)
rm(training, test)
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.factor))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value="MISSING")
}
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.integer))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value=-1)
}
trows = nrow(training)
# install.packages("data.table", type = "source", repos = "http://Rdatatable.github.io/data.table") ## requires recent data.table
library(data.table)
library(caret)
library(plyr)
library(dplyr)
library(dtplyr)
library(tidyr)
library(ggplot2)
setwd("~/GitHub/hprice")
training = fread('train.csv', stringsAsFactors = TRUE)
trows = nrow(training)
test = fread('test.csv', stringsAsFactors = TRUE)
data = rbind(training, test, fill=TRUE)
rm(training, test)
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.factor))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value="MISSING")
}
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.integer))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value=-1)
}
training = data[1:trows, ]
dt.test = data[-seq_len(trows), ]
inTraining = createDataPartition(training$SalePrice, p=3/4, list=FALSE)
dt.train = training[inTraining,]
dt.valid = training[-inTraining,]
rm(training, inTraining)
sapply(df.train,function(x) sum(is.na(x)))
# install.packages("data.table", type = "source", repos = "http://Rdatatable.github.io/data.table") ## requires recent data.table
library(data.table)
library(caret)
library(plyr)
library(dplyr)
library(dtplyr)
library(tidyr)
library(ggplot2)
setwd("~/GitHub/hprice")
training = fread('train.csv', stringsAsFactors = TRUE)
trows = nrow(training)
test = fread('test.csv', stringsAsFactors = TRUE)
data = rbind(training, test, fill=TRUE)
rm(training, test)
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.factor))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value="MISSING")
}
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.integer))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value=-1)
}
training = data[1:trows, ]
dt.test = data[-seq_len(trows), ]
inTraining = createDataPartition(training$SalePrice, p=3/4, list=FALSE)
dt.train = training[inTraining,]
dt.valid = training[-inTraining,]
rm(training, inTraining)
#dummyVars(SalePrice ~., data=df.train)
nzv = nearZeroVar(dt.train, saveMetrics = TRUE)
nzv[nzv$nzv,]
#dropCols = names(df.train)[nzv$nzv]
# keep these two columns
#removeFromDrop = c("KitchenAbvGr", "PoolArea", "PoolQC", "LowQualFinSF", "Functional")
#dropCols[!dropCols %in% removeFromDrop]
# remove the NZV except KitchenAbvGr, PoolArea
#df.train[, (dropCols) := NULL]
sapply(dt.train,function(x) sum(is.na(x)))
fitControl = trainControl(method="cv", repeats=5)
gbm_fitted = train(SalePrice ~., data=df.train, method="gbm", trControl=fitControl, verbose=TRUE)
predict(gbm_fitted, df.valid)
# TotalBsmtSF BsmtExposure
# lot frontage is probably important to price; impute it with rpart
#col.pred = c("MSZoning", "MSSubClass", "LotFrontage", "LotArea", "Alley", "LotShape", "BldgType", "HouseStyle", "YrSold")
#df.frontage_subset = df.train %>% select(one_of(col.pred)) # use one_of to get columns by name
#df.known_frontage = df.frontage_subset %>% filter(!is.na(LotFrontage))
#df.unknown_frontage = df.frontage_subset %>% filter(is.na(LotFrontage))
#fitted_frontage = rpart(LotFrontage ~., data=df.known_frontage)
#predict_frontage = as.integer(melt(predict(fitted_frontage, df.unknown_frontage))$value)
#df.train[is.na(LotFrontage), LotFrontage := predict_frontage]
nzv = nearZeroVar(df.train, saveMetrics = TRUE)
nzv[nzv$nzv,]
train_control = trainControl(method="cv", number=5)
lm.fit = train(SalePrice ~., data=df.train, method="glm", trControl=train_control)
varImp(lm.fit)
sapply(dt.train,function(x) sum(is.na(x)))
fitControl = trainControl(method="cv", repeats=5)
gbm_fitted = train(SalePrice ~., data=df.train, method="gbm", trControl=fitControl, verbose=TRUE)
sapply(dt.train,function(x) sum(is.na(x)))
fitControl = trainControl(method="cv", repeats=5)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, verbose=TRUE)
predict(gbm_fitted, df.valid)
predict(gbm_fitted, dt.valid)
confusionMatrix(dt.valid$SalePrice, gbm_predict)$overall
gbm_predict = predict(gbm_fitted, dt.valid)
confusionMatrix(dt.valid$SalePrice, gbm_predict)$overall
gbm_predict
dt.valid$SalePrice
confusionMatrix(dt.valid$SalePrice, gbm_predict)
table(gbm_predict)
confusionMatrix(gbm_predict,dt.valid$SalePrice)
gbm_predict
dim(dt.valid)
dim(gbm_predict
)
dim(gbm_predict)
len(dt.valid$SalePrice)
length(dt.valid$SalePrice)
dt.valid$SaleType[1:10]
dt.valid$SalePrice[1:10]
gbm_predict[1:10]
round(gbm_predict[1:10])
confusionMatrix(gbm_predict,dt.valid$SalePrice)
gbm_predict = predict(gbm_fitted, dt.valid)
confusionMatrix(dt.valid$SalePrice, gbm_predict)$overall
dt.valid$SalePrice
gbm_predict
confusionMatrix(dt.valid$SalePrice, gbm_predict)$overall
length(gbm_predict)
length(dt.valid$SalePrice)
table(dt.valid$SalePrice, gbm_predict)$overall
table(dt.valid$SalePrice, gbm_predict)
rmse = sqrt(mean( (gbm_predict-gbm_predict)^2))
rmse
rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2))
rmse
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
data[Id, Id := NULL]
data[, Id := NULL]
str(data)
rmse(dt.valid$SalePrice,gbm_predict)
?rmse
fitControl = trainControl(method="none", classProbs=FALSE)
?train
fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=10, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE")
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=1000, interaction.depth=10, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE")
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
?expand.grid
fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=100, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE")
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=100, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE")
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=50, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE")
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=3, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE")
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
warnings()
library(data.table)
library(caret)
library(plyr)
library(dplyr)
library(dtplyr)
library(tidyr)
library(ggplot2)
setwd("~/GitHub/hprice")
training = fread('train.csv', stringsAsFactors = TRUE)
trows = nrow(training)
test = fread('test.csv', stringsAsFactors = TRUE)
data = rbind(training, test, fill=TRUE)
rm(training, test)
data[, Id := NULL]
training = data[1:trows, ]
dt.test = data[-seq_len(trows), ]
inTraining = createDataPartition(training$SalePrice, p=3/4, list=FALSE)
dt.train = training[inTraining,]
dt.valid = training[-inTraining,]
rm(training, inTraining)
#dummyVars(SalePrice ~., data=df.train)
nzv = nearZeroVar(dt.train, saveMetrics = TRUE)
nzv[nzv$nzv,]
#dropCols = names(df.train)[nzv$nzv]
# keep these two columns
#removeFromDrop = c("KitchenAbvGr", "PoolArea", "PoolQC", "LowQualFinSF", "Functional")
#dropCols[!dropCols %in% removeFromDrop]
# remove the NZV except KitchenAbvGr, PoolArea
#df.train[, (dropCols) := NULL]
#fitControl = trainControl(method="cv", repeats=5)
fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=3, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE")
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE", na.action = na.pass)
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=3, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE", na.action = na.pass)
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=3, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE", na.action = na.omit)
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=3, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE", na.action=na.exclude)
gbm_predict = predict(gbm_fitted, dt.valid)
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.factor))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value="MISSING")
}
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.integer))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value=-1)
}
fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=3, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE")
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
# install.packages("data.table", type = "source", repos = "http://Rdatatable.github.io/data.table") ## requires recent data.table
library(data.table)
library(caret)
library(plyr)
library(dplyr)
library(dtplyr)
library(tidyr)
library(ggplot2)
setwd("~/GitHub/hprice")
training = fread('train.csv', stringsAsFactors = TRUE)
trows = nrow(training)
test = fread('test.csv', stringsAsFactors = TRUE)
data = rbind(training, test, fill=TRUE)
rm(training, test)
data[, Id := NULL]
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.factor))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value="MISSING")
}
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.integer))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value=-1)
}
#Make sure there are no NA vals in the data set
sapply(dt.train,function(x) sum(is.na(x)))
training = data[1:trows, ]
dt.test = data[-seq_len(trows), ]
inTraining = createDataPartition(training$SalePrice, p=3/4, list=FALSE)
dt.train = training[inTraining,]
dt.valid = training[-inTraining,]
rm(training, inTraining)
#dummyVars(SalePrice ~., data=df.train)
nzv = nearZeroVar(dt.train, saveMetrics = TRUE)
nzv[nzv$nzv,]
#dropCols = names(df.train)[nzv$nzv]
# keep these two columns
#removeFromDrop = c("KitchenAbvGr", "PoolArea", "PoolQC", "LowQualFinSF", "Functional")
#dropCols[!dropCols %in% removeFromDrop]
# remove the NZV except KitchenAbvGr, PoolArea
#df.train[, (dropCols) := NULL]
#fitControl = trainControl(method="cv", repeats=5)
fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=3, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE")
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
( rmse = mean( (dt.valid$SalePrice - gbm_predict)^2))
mean(residuals(gbm_predict)^2)
residuals(gbm_predict)
gbm_predict
dt.valid$SalePrice-gbm_predict
dt.valid$SalePrice-gbm_predict^2
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
?trainControl
fitControl = trainControl(method="cv", repeats=5, class)
#fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=3, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE")
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
fitControl = trainControl(method="cv", repeats=5, class)
fitControl = trainControl(method="cv", repeats=5)
tuneGrid = expand.grid(n.trees=100, interaction.depth=3, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE")
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
glm.fit = train(SalePrice ~., data=dt.train, method="glm", trControl=train_control)
varImp(glm.fit)
confint(glm.fit)
glm.fit = train(SalePrice ~., data=dt.train, method="glm", trControl=train_control)
glm.fit = train(SalePrice ~., data=dt.train, method="glm", trControl=train_control)
glm.fit = train(SalePrice ~., data=dt.train, method="glm", trControl=fitControl)
confint(glm.fit)
abline(glm.fit,col="red")
glm_fitted = train(SalePrice ~., data=dt.train, method="glm", trControl=fitControl)
glm_predict = predict(glm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - glm_predict)^2)) )
# install.packages("data.table", type = "source", repos = "http://Rdatatable.github.io/data.table") ## requires recent data.table
library(data.table)
library(caret)
library(plyr)
library(dplyr)
library(dtplyr)
library(tidyr)
library(ggplot2)
setwd("~/GitHub/hprice")
training = fread('train.csv', stringsAsFactors = TRUE)
trows = nrow(training)
test = fread('test.csv', stringsAsFactors = TRUE)
data = rbind(training, test, fill=TRUE)
rm(training, test)
data[, Id := NULL]
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.factor))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value="MISSING")
}
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.integer))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value=-1)
}
#Make sure there are no NA vals in the data set
sapply(dt.train,function(x) sum(is.na(x)))
training = data[1:trows, ]
dt.test = data[-seq_len(trows), ]
inTraining = createDataPartition(training$SalePrice, p=3/4, list=FALSE)
dt.train = training[inTraining,]
dt.valid = training[-inTraining,]
rm(training, inTraining)
glm_fitted = train(SalePrice ~., data=dt.train, method="glm", trControl=fitControl)
glm_predict = predict(glm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - glm_predict)^2)) )
nzv[nzv$nzv,]
nzv = nearZeroVar(dt.train, saveMetrics = TRUE)
nzv[nzv$nzv,]
dropCols = names(df.train)[nzv$nzv]
# from dropCols, keep these features..
removeFromDrop = c("KitchenAbvGr", "PoolArea", "PoolQC", "LowQualFinSF", "Functional")
dropCols[!dropCols %in% removeFromDrop]
df.train[, (dropCols) := NULL]
fitControl = trainControl(method="cv", repeats=5)
#fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=3, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE")
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
glm_fitted = train(SalePrice ~., data=dt.train, method="glm", trControl=fitControl)
glm_predict = predict(glm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - glm_predict)^2)) )
nzv = nearZeroVar(dt.train, saveMetrics = TRUE)
nzv[nzv$nzv,]
dropCols = names(dt.train)[nzv$nzv]
# from dropCols, keep these features..
removeFromDrop = c("KitchenAbvGr", "PoolArea", "PoolQC", "LowQualFinSF", "Functional")
dropCols[!dropCols %in% removeFromDrop]
df.train[, (dropCols) := NULL]
nzv = nearZeroVar(dt.train, saveMetrics = TRUE)
nzv[nzv$nzv,]
dropCols = names(dt.train)[nzv$nzv]
# from dropCols, keep these features..
removeFromDrop = c("KitchenAbvGr", "PoolArea", "PoolQC", "LowQualFinSF", "Functional")
dropCols[!dropCols %in% removeFromDrop]
dt.train[, (dropCols) := NULL]
nzv = nearZeroVar(dt.train, saveMetrics = TRUE)
nzv[nzv$nzv,]
dropCols = names(dt.train)[nzv$nzv]
# from dropCols, keep these features..
removeFromDrop = c("KitchenAbvGr", "PoolArea", "PoolQC", "LowQualFinSF", "Functional")
dropCols[!dropCols %in% removeFromDrop]
dt.train[, (dropCols) := NULL]
fitControl = trainControl(method="cv", repeats=5)
#fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=3, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE")
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
library(data.table)
library(caret)
#library(plyr)
library(dplyr)
library(dtplyr)
library(tidyr)
library(ggplot2)
setwd("~/GitHub/hprice")
training = fread('train.csv', stringsAsFactors = TRUE)
trows = nrow(training)
test = fread('test.csv', stringsAsFactors = TRUE)
data = rbind(training, test, fill=TRUE)
rm(training, test)
data[, Id := NULL]
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.factor))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value="MISSING")
}
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.integer))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value=-1)
}
#Make sure there are no NA vals in the data set
sapply(dt.train,function(x) sum(is.na(x)))
training = data[1:trows, ]
dt.test = data[-seq_len(trows), ]
inTraining = createDataPartition(training$SalePrice, p=3/4, list=FALSE)
dt.train = training[inTraining,]
dt.valid = training[-inTraining,]
rm(training, inTraining)
#nzv = nearZeroVar(dt.train, saveMetrics = TRUE)
#nzv[nzv$nzv,]
#dropCols = names(dt.train)[nzv$nzv]
## from dropCols, keep these features..
#removeFromDrop = c("KitchenAbvGr", "PoolArea", "PoolQC", "LowQualFinSF", "Functional")
#dropCols[!dropCols %in% removeFromDrop]
#dt.train[, (dropCols) := NULL]
fitControl = trainControl(method="cv", repeats=5)
#fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=3, shrinkage=0.1, n.minobsinnode=10)
gbm_fitted = train(SalePrice ~., data=dt.train, method="gbm", trControl=fitControl, tuneGrid=tuneGrid, metric="RMSE")
gbm_predict = predict(gbm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - gbm_predict)^2)) )
glm_fitted = train(SalePrice ~., data=dt.train, method="glm", trControl=fitControl)
glm_predict = predict(glm_fitted, dt.valid)
( rmse = sqrt(mean( (dt.valid$SalePrice - glm_predict)^2)) )
# Impute TotalBsmtSF BsmtExposure
# lot frontage is probably important to price; impute it with rpart
#col.pred = c("MSZoning", "MSSubClass", "LotFrontage", "LotArea", "Alley", "LotShape", "BldgType", "HouseStyle", "YrSold")
#dt.frontage_subset = df.train %>% select(one_of(col.pred)) # use one_of to get columns by name
#dt.known_frontage = df.frontage_subset %>% filter(!is.na(LotFrontage))
#dt.unknown_frontage = df.frontage_subset %>% filter(is.na(LotFrontage))
#fitted_frontage = rpart(LotFrontage ~., data=df.known_frontage)
#predict_frontage = as.integer(melt(predict(fitted_frontage, df.unknown_frontage))$value)
#dt.train[is.na(LotFrontage), LotFrontage := predict_frontage]
#library(data.table)
library(caret)
#library(plyr)
library(dplyr)
library(dtplyr)
#library(tidyr)
setwd("~/GitHub/hprice")
training = fread('train.csv', stringsAsFactors = TRUE)
trows = nrow(training)
test = fread('test.csv', stringsAsFactors = TRUE)
data = rbind(training, test, fill=TRUE)
rm(training, test)
data[, Id := NULL]
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.factor))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value="MISSING")
}
#get indexes for all the columns that are of type factor
charIdx = which(sapply(data, is.integer))
for(i in charIdx) {
set(data, i=which(is.na(data[[i]])), j=i, value=-1)
}
#Make sure there are no NA vals in the data set
sapply(dt.train,function(x) sum(is.na(x)))
training = data[1:trows, ]
dt.test = data[-seq_len(trows), ]
inTraining = createDataPartition(training$SalePrice, p=3/4, list=FALSE)
dt.train = training[inTraining,]
dt.valid = training[-inTraining,]
rm(training, inTraining)
#nzv = nearZeroVar(dt.train, saveMetrics = TRUE)
#nzv[nzv$nzv,]
#dropCols = names(dt.train)[nzv$nzv]
## from dropCols, keep these features..
#removeFromDrop = c("KitchenAbvGr", "PoolArea", "PoolQC", "LowQualFinSF", "Functional")
#dropCols[!dropCols %in% removeFromDrop]
#dt.train[, (dropCols) := NULL]
fitControl = trainControl(method="cv", repeats=5)
#fitControl = trainControl(method="none", classProbs=FALSE, verboseIter = TRUE)
tuneGrid = expand.grid(n.trees=100, interaction.depth=3, shrinkage=0.1, n.minobsinnode=10)
?library
